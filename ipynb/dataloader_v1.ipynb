{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "dataloader_v1.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "pycharm-27e57620",
   "language": "python",
   "display_name": "PyCharm (xray_jik)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/swecomic/xray/blob/master/dataloader_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fwoytwg5GtZh",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "outputId": "bb26315d-bf77-4a2b-e354-819e6da140a2"
   },
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### path to your own data and coco file ###\n",
    "\n",
    "# A. Ububtu Path\n",
    "# train_data_dir = '/data/jiylee/dataset/xray/Train/Data'\n",
    "# train_coco = '/data/jiylee/dataset/xray/Train/Meta/CoCo/coco_rapiscan.json'\n",
    "\n",
    "# B. Colab Path\n",
    "train_data_dir = '/content/drive/' + 'Shared drives' + '/YS_NW/2.Data/Train/Data'\n",
    "train_coco = '/content/drive/Shared drives/YS_NW/2.Data/Train/Meta/CoCo/coco_rapiscan.json'\n",
    "\n",
    "class xrayDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root, annotation, class_nm=None, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.coco = COCO(annotation)\n",
    "        self.class_nm = class_nm\n",
    "\n",
    "        # All images or a subset?\n",
    "        if self.class_nm:\n",
    "            class_id = sorted(self.coco.getCatIds(catNms=self.class_nm))\n",
    "            self.ids = []\n",
    "\n",
    "            for id in class_id:\n",
    "                temp_id = self.coco.getImgIds(catIds=[id])\n",
    "                # 공유폴더에 이미지가 존재하는것만 index를 만들어줌\n",
    "                for i in temp_id:\n",
    "                    fname = self.coco.imgs[i]['path'].split('\\\\', maxsplit=7)[-1].replace('\\\\', '/')\n",
    "\n",
    "                    if os.path.isfile(os.path.join(self.root, fname)):\n",
    "                        self.ids.append(i)\n",
    "            # Remove duplicates\n",
    "            self.ids = list(set(self.ids))\n",
    "        else:\n",
    "            # All images\n",
    "            self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "        # All images or a subs)et?\n",
    "        # if self.class_nm:\n",
    "        #     class_id = sorted(self.coco.getCatIds(catNms=self.class_nm))\n",
    "        #     self.ids = []\n",
    "        #     for id in class_id:\n",
    "        #         self.ids.extend(list(self.coco.getImgIds(catIds=[id])))\n",
    "        #     # Remove duplicates\n",
    "        #     self.ids = list(set(self.ids))\n",
    "        # else:\n",
    "        #     # All images\n",
    "        #     self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Own coco file\n",
    "        coco = self.coco\n",
    "\n",
    "        # Image ID\n",
    "        img_id = self.ids[index]\n",
    "\n",
    "        # List: get annotation id from coco\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "\n",
    "        # Dictionary: target coco_annotation file for an image\n",
    "        coco_annotation = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Load Image\n",
    "        img_info = coco.loadImgs(coco_annotation[0][\"image_id\"])\n",
    "\n",
    "        # file path\n",
    "        file_path = img_info[0][\"path\"].split('\\\\', maxsplit=7)[-1]\n",
    "\n",
    "        # open the input image\n",
    "        image_path = os.path.join(self.root, file_path.replace('\\\\', '/'))\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        # number of objects in the image\n",
    "        num_objs = len(coco_annotation)\n",
    "\n",
    "        # Bounding boxes for objects\n",
    "        # In coco format, bbox = [xmin, ymin, width, height]\n",
    "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
    "        boxes = []\n",
    "        class_id = []\n",
    "        for i in range(num_objs):\n",
    "            # bbox\n",
    "            xmin = coco_annotation[i]['bbox'][0]\n",
    "            ymin = coco_annotation[i]['bbox'][1]\n",
    "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
    "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            # class_id\n",
    "            cid = coco_annotation[i][\"category_id\"]\n",
    "            class_id.append(cid)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        class_id = torch.as_tensor(class_id)\n",
    "\n",
    "        image_id = coco_annotation[0][\"image_id\"]\n",
    "        file_name = img_info[0][\"file_name\"]\n",
    "\n",
    "        # Tensorise\n",
    "        image_id = torch.tensor([image_id])\n",
    "        # file_name = torch.tensor([file_name])\n",
    "\n",
    "        # Annotation is in dictionary format\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"class_id\"] = class_id\n",
    "        my_annotation[\"image_id\"] = image_id\n",
    "        # my_annotation[\"file_name\"] = file_name\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "# just added ToTensor\n",
    "def get_transform():\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    return torchvision.transforms.Compose(custom_transforms)\n",
    "\n",
    "# show image\n",
    "def show_image(sample_img, sample_anno):\n",
    "    plt.imshow(sample_img)\n",
    "\n",
    "    # bbox\n",
    "    bb = np.array(sample_anno[\"boxes\"], dtype=np.float32)\n",
    "    for j in range(len(bb)):\n",
    "        line = plt.Rectangle((bb[j][0], bb[j][1]), bb[j][2] - bb[j][0], bb[j][3] - bb[j][1], color=\"red\", fill=False,\n",
    "                             lw=1)\n",
    "        plt.gca().add_patch(line)\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "# create own Dataset\n",
    "class_nm = ['Battery']\n",
    "my_dataset = xrayDataset(root=train_data_dir,\n",
    "                         annotation=train_coco,\n",
    "                         class_nm=class_nm,\n",
    "                         transforms=get_transform()\n",
    "                         )\n",
    "\n",
    "# Batch size\n",
    "train_batch_size = 32\n",
    "\n",
    "# own DataLoader\n",
    "data_loader = torch.utils.data.DataLoader(my_dataset,\n",
    "                                          batch_size=train_batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# DataLoader is iterable over Dataset\n",
    "for imgs, annotations in data_loader:\n",
    "    imgs = list(img.to(device) for img in imgs)\n",
    "    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "    # print(annotations)\n",
    "\n",
    "\n",
    "# show random 3 images\n",
    "random_sample = random.sample(range(0, len(my_dataset)-1), 3)\n",
    "for i in random_sample:\n",
    "\n",
    "    sample_img = np.array(my_dataset[i][0].permute(1, 2, 0), dtype=np.float32)\n",
    "    sample_anno = my_dataset[i][1]\n",
    "\n",
    "    show_image(sample_img, sample_anno)\n",
    "    plt.show()\n",
    "\n",
    "    if i ==3:\n",
    "        break\n"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_utils_internal'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-6d9723e0b51b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mPIL\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mImage\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\xray_jik\\lib\\site-packages\\torchvision\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mextension\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_HAS_OPS\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\xray_jik\\lib\\site-packages\\torchvision\\extension.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m     \u001B[0m_register_extensions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m     \u001B[0m_HAS_OPS\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mImportError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mOSError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\xray_jik\\lib\\site-packages\\torchvision\\extension.py\u001B[0m in \u001B[0;36m_register_extensions\u001B[1;34m()\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mext_specs\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mImportError\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m     \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_library\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mext_specs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0morigin\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\xray_jik\\lib\\site-packages\\torch\\_ops.py\u001B[0m in \u001B[0;36mload_library\u001B[1;34m(self, path)\u001B[0m\n\u001B[0;32m     98\u001B[0m             \u001B[0mpath\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mA\u001B[0m \u001B[0mpath\u001B[0m \u001B[0mto\u001B[0m \u001B[0ma\u001B[0m \u001B[0mshared\u001B[0m \u001B[0mlibrary\u001B[0m \u001B[0mto\u001B[0m \u001B[0mload\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     99\u001B[0m         \"\"\"\n\u001B[1;32m--> 100\u001B[1;33m         \u001B[0mpath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_utils_internal\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresolve_library_path\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    101\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mdl_open_guard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    102\u001B[0m             \u001B[1;31m# Import the shared library into the process, thus running its\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch' has no attribute '_utils_internal'"
     ]
    }
   ]
  }
 ]
}